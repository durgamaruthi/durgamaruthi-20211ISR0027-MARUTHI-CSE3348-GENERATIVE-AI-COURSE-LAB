{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de1209d-a43f-498d-9792-064f2749bd31",
   "metadata": {},
   "source": [
    "# date : 30-9-24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ce5db5-ba04-41f2-9213-251f4a317c25",
   "metadata": {},
   "source": [
    "## # labsheet -7\n",
    "# NAME : P.DURGA MARUTHI VARA PRASAD\n",
    "# ROLL.NO : 20211ISR0027\n",
    "# SECTION:7-ISR-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f2e140-ec33-4f34-acf1-ce1c75f6bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain-openai\n",
    "#pip install langchain\n",
    "#pip install openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc7a16a-1cec-47c8-b2c0-61ef343ab14e",
   "metadata": {},
   "source": [
    "# Ex1 : Simple Sequential LLM CHains - Chains with single input and single output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da9a90f-0790-4d82-a88e-8770630048bd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3n/1_0p1w191rb_3clrsh33yc9h0000gn/T/ipykernel_72893/1285828418.py:21: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  chain1 = LLMChain(llm=llm, prompt = prompt1)\n",
      "/var/folders/3n/1_0p1w191rb_3clrsh33yc9h0000gn/T/ipykernel_72893/1285828418.py:47: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  response = final_chain.run(\"Noodles\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "\"NoodleNation Co.\" \u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "\"Satisfy your cravings with NoodleNation Co.\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\"Satisfy your cravings with NoodleNation Co.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    " \n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    " \n",
    "\n",
    "llm = OpenAI(temperature = 0.9)\n",
    "\n",
    " \n",
    "\n",
    "template = \"Suggest a good name for a company that makes {product}\"\n",
    "\n",
    "prompt1 = PromptTemplate.from_template(template)\n",
    "\n",
    "chain1 = LLMChain(llm=llm, prompt = prompt1)\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "template = \"Generate a catchy phrase for this company {company}\"\n",
    "\n",
    "prompt2 = PromptTemplate.from_template(template)\n",
    "\n",
    "chain2 = LLMChain(llm=llm, prompt = prompt2)\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "final_chain = SimpleSequentialChain(\n",
    "\n",
    "   \n",
    "\n",
    "   chains = [chain1,chain2],\n",
    "\n",
    "   verbose = True)\n",
    "\n",
    " \n",
    "\n",
    "response = final_chain.run(\"Noodles\")\n",
    "\n",
    "         \n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4198a0-dff9-40f5-9088-3e65b478468d",
   "metadata": {},
   "source": [
    "# SEQUENTIAL CHAIN\n",
    "\n",
    "__**HE TOP 5 CAR MODELS OF THAT YEAR**__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00d6c4c7-0127-4842-9ea9-7ac2a381d478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3n/1_0p1w191rb_3clrsh33yc9h0000gn/T/ipykernel_72893/2990665566.py:51: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  response = final_chain({\"name\": \"Ford\"})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mTell me when the car model Ford was launched\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mTell me the top 5 car model in the year \n",
      "\n",
      "The first Ford car, the Model A, was launched in 1903. However, the first mass-produced car by Ford, the Model T, was launched in 1908.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'name': 'Ford', 'year': '\\n\\nThe first Ford car, the Model A, was launched in 1903. However, the first mass-produced car by Ford, the Model T, was launched in 1908.', 'top 5': ' Therefore, it is difficult to determine the top 5 car models in a specific year without specifying the year. \\n\\nSome popular car models from recent years include:\\n\\n1. Toyota Corolla\\n2. Honda Civic\\n3. Ford F-Series\\n4. Chevrolet Silverado\\n5. Toyota RAV4'}\n"
     ]
    }
   ],
   "source": [
    "#Sequential chain with single input and single output variable\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "\n",
    " \n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    " \n",
    "\n",
    "llm = OpenAI(temperature = 0.5)\n",
    "\n",
    "prompt1 = PromptTemplate(\n",
    "\n",
    "             input_variables = ['name'],\n",
    "\n",
    "             template = \"Tell me when the car model {name} was launched\"\n",
    "\n",
    "             )\n",
    "\n",
    "chain1 = LLMChain(llm = llm, prompt = prompt1, verbose = True, output_key = 'year')\n",
    "\n",
    " \n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "\n",
    "         input_variables = [\"year\"],\n",
    "\n",
    "         template = \"Tell me the top 5 car model in the year {year}\"\n",
    "\n",
    "         )\n",
    "\n",
    "chain2 = LLMChain(llm = llm, prompt =  prompt2, verbose = True, output_key = 'top 5')\n",
    "\n",
    " \n",
    "\n",
    "final_chain = SequentialChain(\n",
    "\n",
    "      chains = [chain1,chain2],\n",
    "\n",
    "      input_variables = ['name'],\n",
    "\n",
    "      output_variables = ['year', 'top 5'], verbose = True)\n",
    "\n",
    " \n",
    "\n",
    "response = final_chain({\"name\": \"Ford\"})\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bc0fa8-c8b4-4f9c-a927-72f479f71b31",
   "metadata": {},
   "source": [
    "# __Ex3 FIND THE YEAR WHEN “FORD” LAUNCHED “ECO-SPORT”. FIND SIMILAR PRODUCTS LAUNCHED IN THAT YEAR__\n",
    "\n",
    "# __With multiple input Variables__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f983db6-508c-4424-80ed-ea10407a23bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mTell me when the Ford launched the product Eco_sport?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mList four similar products launched in the year \n",
      "\n",
      "The Ford EcoSport was launched in 2013.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'company': 'Ford', 'product_name': 'Eco_sport', 'year': '\\n\\nThe Ford EcoSport was launched in 2013.', 'four similar': ' Four other similar products launched in the same year are:\\n\\n1. Chevrolet Trax\\n2. Honda HR-V\\n3. Mazda CX-5\\n4. Nissan Juke'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "\n",
    " \n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    " \n",
    "\n",
    "llm = OpenAI(temperature = 0.5)\n",
    "\n",
    "prompt1 = PromptTemplate(\n",
    "\n",
    "             input_variables = ['company', 'product_name'],\n",
    "\n",
    "             template = \"Tell me when the {company} launched the product {product_name}?\"\n",
    "\n",
    "             )\n",
    "\n",
    "chain1 = LLMChain(llm = llm, prompt = prompt1, verbose = True, output_key = 'year')\n",
    "\n",
    " \n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "\n",
    "         input_variables = [\"year\"],\n",
    "\n",
    "         template = \"List four similar products launched in the year {year}\"\n",
    "\n",
    "         )\n",
    "\n",
    "chain2 = LLMChain(llm = llm, prompt =  prompt2, verbose = True, output_key = 'four similar')\n",
    "\n",
    " \n",
    "\n",
    "final_chain = SequentialChain(\n",
    "\n",
    "      chains = [chain1,chain2],\n",
    "\n",
    "      input_variables = ['company', 'product_name'],\n",
    "\n",
    "      output_variables = ['year', 'four similar'], verbose = True)\n",
    "\n",
    " \n",
    "\n",
    "response = final_chain({\"company\": \"Ford\", \"product_name\":\"Eco_sport\" })\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df265fe-27d2-49c1-ae11-e61281878e33",
   "metadata": {},
   "source": [
    "# Ex4 : Sequential Chains - Chains with multiple inputs and Outputs\n",
    "\n",
    " \n",
    "\n",
    "PROBLEM: TRANSLATE THE GIVEN REVIEW To ENGLISH. SUMMARIZE IT. FIND THE LANGUAGE IN WHICH THE REVIEW IS WRITTEN. WRITE A FOLLOW UP RESPONSE TO THE SUMARY IN A GIVEN LANGUAGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9254c12-f285-441a-884c-308b89227acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Language of the given review is \n",
      "\n",
      "The language used in the review appears to be French.\n",
      "\n",
      "Review translated to English is: \n",
      "\n",
      "GamersTech laptops impress with their exceptional performance and elegant design. From its robust hardware configuration to a customizable RGB keyboard and efficient cooling system, it strikes a perfect balance between gaming prowess and portability.\n",
      "\n",
      "Summary of the review is \n",
      "\n",
      "GamersTech laptops impress with their exceptional performance and elegant design. From its robust hardware configuration to a customizable RGB keyboard and efficient cooling system, it strikes a perfect balance between gaming prowess and portability.\n",
      "\n",
      "A follow-up message of the review summary is \n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    " \n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    " \n",
    "\n",
    "llm = OpenAI(temperature = 0.8)\n",
    "\n",
    " \n",
    "\n",
    "Review = \"\"\"Les ordinateurs portables GamersTech impressionne par ses\n",
    "\n",
    "performances exceptionnelles et son design élégant. De sa configuration  \n",
    "\n",
    "matérielle robuste à un clavier RVB personnalisable et un système de  \n",
    "\n",
    "refroidissement efficace, il établit un équilibre parfait entre prouesses  \n",
    "\n",
    "de jeu et portabilité.\"\"\" \n",
    "\n",
    " \n",
    "\n",
    "#Promp Template 1 : Translate the review to English\n",
    "\n",
    " \n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\n",
    "\n",
    "   \"Translate the following to English:\"\n",
    "\n",
    "   \"\\n\\n{Review}\"\n",
    "\n",
    "   \n",
    "\n",
    "   )\n",
    "\n",
    "#Chain 1 : Input : Review  Output : Eng_review\n",
    "\n",
    "chain1 = LLMChain(llm = llm, prompt = prompt1, output_key = \"Eng_review\")\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "#Promp Template 2 : Summarize the translated review\n",
    "\n",
    " \n",
    "\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "\n",
    "   \"Summarize the following review in 1 sentence\"\n",
    "\n",
    "   \"\\n\\n{Eng_review}\"\n",
    "\n",
    "   \n",
    "\n",
    "   )\n",
    "\n",
    "#Chain 2 : Input : Eng_review  Output : Summary\n",
    "\n",
    "chain2 = LLMChain(llm = llm, prompt = prompt1, output_key = \"Summary\")\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "#Promp Template 3 : Find the language in which the review is written\n",
    "\n",
    " \n",
    "\n",
    "prompt3 = ChatPromptTemplate.from_template(\n",
    "\n",
    "   \"What is the language in which the review is written\"\n",
    "\n",
    "   \"\\n\\n{Review}\"\n",
    "\n",
    "   \n",
    "\n",
    "   )\n",
    "\n",
    "#Chain 3 : Input : Review  Output : language\n",
    "\n",
    "chain3 = LLMChain(llm = llm, prompt = prompt3, output_key = \"language\")\n",
    "\n",
    " \n",
    "\n",
    "#Promp Template 4 : Write a follow up response to the summary in the language given\n",
    "\n",
    " \n",
    "\n",
    "prompt4 = ChatPromptTemplate.from_template(\n",
    "\n",
    "   \"Write a follow up response to the following summary\"\n",
    "\n",
    "   \"In the specified language\"\n",
    "\n",
    "   \"\\n\\nSummary : {Summary}\\n\\n Language : {language}\"\n",
    "\n",
    "   \n",
    "\n",
    "   )\n",
    "\n",
    " \n",
    "\n",
    "#Chain 4 : Input : Summary, Language,  Output : followup_message\n",
    "\n",
    "chain4 = LLMChain(llm = llm, prompt = prompt4, output_key = \"followup_message\")\n",
    "\n",
    " \n",
    "\n",
    "final_chain = SequentialChain(\n",
    "\n",
    "   \n",
    "\n",
    "   chains = [chain1,chain2,chain3,chain4],\n",
    "\n",
    "   input_variables = [\"Review\"],\n",
    "\n",
    "   output_variables = [\"Eng_review\", \"Summary\", \"language\", \"followup_message\"],\n",
    "\n",
    "   verbose = True)\n",
    "\n",
    " \n",
    "\n",
    "response = final_chain(Review)\n",
    "\n",
    "         \n",
    "\n",
    "print(\"Language of the given review is\", response['language'])\n",
    "\n",
    "print(\"\\nReview translated to English is:\", response['Eng_review'])\n",
    "\n",
    " \n",
    "\n",
    "print(\"\\nSummary of the review is\", response['Summary'])\n",
    "\n",
    "print(\"\\nA follow-up message of the review summary is\", response['followup_message'])\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42299da0-a42d-4c96-b442-6d893d18ec1f",
   "metadata": {},
   "source": [
    "# there would be total 3 set of question paper \n",
    "# write labsheet-1,2,3,4,7 before the labexam , or probably the next lab. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
