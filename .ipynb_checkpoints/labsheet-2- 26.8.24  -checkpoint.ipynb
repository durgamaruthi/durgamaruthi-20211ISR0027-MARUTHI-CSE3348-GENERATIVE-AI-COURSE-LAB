{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b8093-6831-4cc3-b2ee-d4e78cad2240",
   "metadata": {},
   "outputs": [],
   "source": [
    " lab date : 26.8.24 , 3-9-24 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc463e87-9afe-44e2-9978-d8111dbe8108",
   "metadata": {},
   "source": [
    "# labsheet -2\n",
    "# NAME : P.DURGA MARUTHI VARA PRASAD\n",
    "# ROLL.NO : 20211ISR0027\n",
    "# SECTION:7-ISR-01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9b6c1d-7f3a-4fd1-adfc-8b6aebd8bada",
   "metadata": {},
   "source": [
    " # ex-1 text summarization \n",
    " Ex 1: Text Summarisation\n",
    "Problem Statement: Summarise the minutes of the meeting given below in 4 bullet points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b613e02a-9a53-4a9f-97d8-bc5b40798033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Meeting called to order by Bharath Thippireddy\n",
      "- Previous meeting minutes approved\n",
      "- CEO's report highlighted sales figures, cost reduction initiatives, and industry events\n",
      "- Financial report presented by CFO, discussing revenue, profit margins, budget vs actual expenditure, and cash flow analysis\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "instruction = \"\"\" Summarise the minutes of the meeting given\n",
    " below in 4 bullet points:\n",
    "                  Car Manufacturing Company\n",
    "\n",
    "Board of Directors Meeting Minutes\n",
    "\n",
    "Agenda:\n",
    "1. Call to Order\n",
    "2. Approval of Previous Meeting Minutes\n",
    "3. CEO's Report\n",
    "4. Financial Report\n",
    "\n",
    "Meeting Minutes:\n",
    "\n",
    "1. Call to Order:\n",
    "   - The meeting was called to order by Bharath Thippireddy.\n",
    "\n",
    "2. Approval of Previous Meeting Minutes:\n",
    "   - The minutes of the previous board meeting, held on [Date],\n",
    " were reviewed and approved.\n",
    "\n",
    "3. CEO's Report:\n",
    "   - Bharath Thippireddy presented an overview of the company's performance, highlighting key achievements and challenges. Key points discussed include:\n",
    "     - Sales figures for the last quarter.\n",
    "     - Progress on cost reduction initiatives.\n",
    "     - Highlights from recent industry events.\n",
    "   - The CEO answered questions from board members.\n",
    "\n",
    "4. Financial Report:\n",
    "   - The Chief Financial Officer ([CFO's Name]) presented the financial report. Key financial metrics discussed include:\n",
    "     - Revenue and profit margins.\n",
    "     - Budget vs. actual expenditure.\n",
    "     - Cash flow analysis.\n",
    "   - The board discussed financial performance and the impact on shareholder value.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "   \n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": instruction\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "  \n",
    "  ],\n",
    "  temperature=1,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "#print(response)\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc8ad54-abdd-4513-b71b-242e29cfc203",
   "metadata": {},
   "source": [
    "# ex -2 \n",
    "# problem : TEXT CLASSIFICATION\n",
    "\n",
    "classify the companies given below: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adbaaf6f-8054-4c9e-8661-a0a1b163c7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tech Companies: Microsoft Corporation, Apple Inc, Amazon.com, Inc\n",
      "\n",
      "Pharmaceutical Companies: Roche Holding AG, Pfizer Inc, Johnson & Johnson\n",
      "\n",
      "Financial Institutions: JPMorgan Chase & Co, Bank of America Corporation, Industrial and Commercial Bank of China\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    \n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"Categorise the companies given : \"\n",
    "          \"Microsoft Corporation, Roche Holding AG, Apple Inc\"\n",
    "          \"Amazon.com, Inc,Pfizer Inc, JPMorgan Chase & Co.\"\n",
    "          \"Johnson & Johnson, Bank of America Corporation, Industrial and Commercial Bank of China .\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "  \n",
    "  ],\n",
    "  \n",
    "   \n",
    "  max_tokens=300,\n",
    "  \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538e74ad-0b17-4ae5-ab78-bf49669f5d5b",
   "metadata": {},
   "source": [
    "# ex3 - sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3ea0718-afa5-44e6-9b17-ad949116f9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Positive - The user expresses love for the new XPhone, specifically highlighting the camera and battery life. They use positive emojis and hashtags to convey their excitement and satisfaction.\n",
      "2. Negative - The user is disappointed with the XPhone, finding it pricey and not meeting their expectations. They express their disappointment with a sad emoji and use the hashtag #TechTalk to share their negative opinion.\n",
      "3. Positive - The user is thrilled with XPhone's latest update, emphasizing the incredible graphics for mobile gaming. They use emojis and the hashtag #GameChanger to show their positive sentiment.\n",
      "4. Negative - The user finds the XPhone underwhelming and overpriced, ultimately deciding to go back to their old phone. They express their dissatisfaction with a disappointed emoji and mention that they waited a long time for the XPhone, indicating unmet expectations.\n",
      "5. Positive - The user is impressed with the XPhone, stating that it has exceeded their expectations. They highlight its speed, sleek design, and new AI features, using emojis and the hashtag #Innovation to convey their positive sentiment.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"\"\"Below are several social media posts. For each post, please analyze the sentiment expressed and classify it as either positive, negative, or neutral. Provide a brief explanation for your classification\"\n",
    "                  \"1. Just got my hands on the new XPhone - absolutely loving the camera and battery life! 📸🔋 #TechLove\n",
    "2. Disappointed with the XPhone. Its pricey and not much different from the last model. Expected more. 😕 #TechTalk\n",
    "3. XPhones latest update is a game-changer for mobile gaming. The graphics are just incredible! 🎮💯\n",
    "4. Cant believe I waited this long for the XPhone... its underwhelming and overpriced. Back to my old phone, I guess. 😒\n",
    "5. The XPhone has exceeded my expectations. Fast, sleek, and the new AI features are a standout! 🚀 #Innovation\"\"\"\n",
    "\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "  \n",
    "  ],\n",
    "  \n",
    "   \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(response.choices[0].message.content) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26f8f65-1427-49c3-8917-d930c7633f19",
   "metadata": {},
   "source": [
    "# ex-4 generating multiple response\n",
    "problem : generative 3 recipes for baking a cake \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba80c74f-fa50-435d-92f3-74998a9177fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe :  1\n",
      "**************\n",
      "Sure! Here's a simple recipe for a classic vanilla cake:\n",
      "\n",
      "Ingredients:\n",
      "- 1 3/4 cups all-purpose flour\n",
      "- 1 cup granulated sugar\n",
      "- 1/2 cup unsalted butter, softened\n",
      "- 2 large eggs\n",
      "- 1 teaspoon vanilla extract\n",
      "- 1 1/2 teaspoons baking powder\n",
      "- 1/2 teaspoon salt\n",
      "- 1/2 cup milk\n",
      "\n",
      "Instructions:\n",
      "1. Preheat your oven to 350°F (175°C) and grease and flour a 9-inch round cake pan.\n",
      "2. In a mixing bowl, cream together the butter and sugar until light and fluffy.\n",
      "3. Add the eggs one at a time, beating well after each addition. Stir in the vanilla extract.\n",
      "4. In a separate bowl, sift together the flour, baking powder, and salt.\n",
      "5. Gradually add the dry ingredients to the wet ingredients, alternating with the milk, until just combined.\n",
      "6. Pour the batter into the prepared cake pan and smooth the top with a spatula.\n",
      "7. Bake in the preheated oven for 25-30 minutes, or until a toothpick inserted into the center of the cake comes out clean.\n",
      "8. Allow the cake to cool in the pan for 10 minutes before transferring to a wire rack to cool completely.\n",
      "9. Frost and decorate the cake as desired.\n",
      "\n",
      "Enjoy your homemade vanilla cake!\n",
      "Recipe :  2\n",
      "**************\n",
      "Sure! Here is a simple recipe for a classic vanilla cake:\n",
      "\n",
      "Ingredients:\n",
      "- 2 1/2 cups all-purpose flour\n",
      "- 1 1/2 cups sugar\n",
      "- 1 cup unsalted butter, softened\n",
      "- 4 eggs\n",
      "- 1 cup milk\n",
      "- 2 teaspoons vanilla extract\n",
      "- 2 1/2 teaspoons baking powder\n",
      "- 1/2 teaspoon salt\n",
      "\n",
      "Instructions:\n",
      "1. Preheat your oven to 350°F (175°C). Grease and flour two 9-inch round cake pans.\n",
      "2. In a medium bowl, whisk together the flour, baking powder, and salt. Set aside.\n",
      "3. In a large mixing bowl, cream together the butter and sugar until light and fluffy.\n",
      "4. Add the eggs one at a time, mixing well after each addition. Stir in the vanilla extract.\n",
      "5. Gradually mix in the flour mixture, alternating with the milk, starting and ending with the flour.\n",
      "6. Pour the batter into the prepared cake pans and smooth the tops.\n",
      "7. Bake in the preheated oven for 25-30 minutes, or until a toothpick inserted into the center comes out clean.\n",
      "8. Remove from the oven and let the cakes cool in the pans for 10 minutes. Then transfer them to a wire rack to cool completely before frosting.\n",
      "\n",
      "Feel free to frost the cake with your favorite frosting, such as vanilla buttercream or cream cheese frosting. Enjoy your delicious homemade vanilla cake!\n",
      "Recipe :  3\n",
      "**************\n",
      "Sure! Here's a classic vanilla cake recipe that you can easily follow:\n",
      "\n",
      "Ingredients:\n",
      "- 1 and 3/4 cups all-purpose flour\n",
      "- 1 and 1/2 teaspoons baking powder\n",
      "- 1/2 teaspoon baking soda\n",
      "- 1/2 teaspoon salt\n",
      "- 1/2 cup unsalted butter, softened\n",
      "- 1 cup granulated sugar\n",
      "- 2 large eggs, room temperature\n",
      "- 1 and 1/2 teaspoons vanilla extract\n",
      "- 1/2 cup buttermilk, room temperature\n",
      "\n",
      "Instructions:\n",
      "1. Preheat your oven to 350°F (180°C). Grease and flour two 8-inch round cake pans.\n",
      "2. In a medium bowl, whisk together the flour, baking powder, baking soda, and salt.\n",
      "3. In a large bowl, cream together the butter and sugar until light and fluffy.\n",
      "4. Beat in the eggs one at a time, then stir in the vanilla extract.\n",
      "5. Gradually mix in the dry ingredients, alternating with the buttermilk, starting and ending with the dry ingredients.\n",
      "6. Divide the batter evenly between the prepared cake pans.\n",
      "7. Bake in the preheated oven for 25-30 minutes, or until a toothpick inserted into the center comes out clean.\n",
      "8. Allow the cakes to cool in the pans for 10 minutes, then transfer them to a wire rack to cool completely before frosting.\n",
      "\n",
      "You can frost the cake with your favorite\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"You are a cake baker\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"Get me a recipe to bake a cake\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "  \n",
    "  ],\n",
    "  \n",
    "  n=3,\n",
    "  \n",
    "  max_tokens=300,\n",
    "  \n",
    ")\n",
    "\n",
    "#print(response)\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"Recipe : \", i+1)\n",
    "    print(\"**************\")\n",
    "    print(response.choices[i].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dfd259-c61e-4a6c-bff8-94896975f1ca",
   "metadata": {},
   "source": [
    "# ex 5 - code explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4cb37e7-8d98-4de8-b04f-6a6711eb8d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Python code takes a number as input and determines whether or not it is a prime number.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "instruction = \"\"\"Explain what this Python code does in one sentence:\n",
    "number = int(input(\"Enter a number:\"))\n",
    "primeFlag = True\n",
    "for i in range(2, number):\n",
    "    if number % i == 0:\n",
    "        primeFlag = False\n",
    "        break\n",
    "if primeFlag == True:\n",
    "    print(number, \" is prime.\")\n",
    "else:\n",
    "    print(number, \" is not prime.\")\n",
    "    \"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": instruction\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "  ],\n",
    "  max_tokens=300\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a1684e-c7de-44cd-a00c-a455506b0908",
   "metadata": {},
   "source": [
    "# exp-6 , error handling \n",
    "PROBLEM: THROW AN EXPECTION IF THE API KEY FAILS TO GET AUTHENTICATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e02616bd-c5e9-4cb6-9325-76a04ad52c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: HTTPSConnectionPool(host='api.example.com', port=443): Max retries exceeded with url: /data (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x11401c710>: Failed to resolve 'api.example.com' ([Errno 8] nodename nor servname provided, or not known)\"))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def make_api_request(api_key, url):\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {api_key}'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raises an HTTPError for bad responses (4xx or 5xx)\n",
    "        \n",
    "        # Process the response if successful\n",
    "        return response.json()\n",
    "    \n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        if response.status_code == 401:\n",
    "            raise Exception(\"Authentication failed: Invalid API key.\") from http_err\n",
    "        elif response.status_code == 403:\n",
    "            raise Exception(\"Access denied: API key does not have permission.\") from http_err\n",
    "        else:\n",
    "            raise Exception(f\"HTTP error occurred: {http_err}\") from http_err\n",
    "    except Exception as err:\n",
    "        raise Exception(f\"An error occurred: {err}\")\n",
    "\n",
    "# Example usage\n",
    "api_key = 'your_api_key_here'\n",
    "url = 'https://api.example.com/data'\n",
    "try:\n",
    "    data = make_api_request(api_key, url)\n",
    "    print(data)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4b986e-75ef-4c8e-94d5-dcf13d0e58e7",
   "metadata": {},
   "source": [
    "# EXP 7 CHATBOT APPLICATION\n",
    "PROBLEM :CREATE A MATHS TUTOR AS A CHATBOT TO ANSWER SOME QUESTIONS IN MKATHS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0af8792-8f00-4e9a-b817-31e26e54e8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi (π) is a mathematical constant that represents the ratio of a circle's circumference to its diameter. It is an irrational number, meaning it cannot be expressed as a simple fraction, and its decimal representation goes on infinitely without repeating. Pi is approximately equal to 3.14159, though it is usually rounded to 3.14 for practical calculations. It is an important constant in mathematics and is used in a wide range of mathematical formulas and calculations involving circles and geometry.\n",
      "- Pi (π) is a mathematical constant representing the ratio of a circle's circumference to its diameter\n",
      "- It is an irrational number approximately equal to 3.14159, used in various mathematical calculations involving circles and geometry.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI() \n",
    "\n",
    "messages = [ {'role':'system', 'content':\"You are a Math Tutor\"}]\n",
    "user_messages = ['Explain what is PI', 'Summarize this in two bullet points']\n",
    "\n",
    "for each_message in user_messages:\n",
    "    user_dict = {'role': 'user', 'content':[{'type': 'text', 'text': each_message}]}\n",
    "    messages.append(user_dict)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "               model=\"gpt-3.5-turbo\",\n",
    "    messages=messages)\n",
    "    \n",
    "    assist_dict ={'role':'assistant', 'content': [{'type': 'text', 'text': response.choices[0].message.content}]}\n",
    "    messages.append(assist_dict)\n",
    "    \n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4ae4f3-d0d2-4d6c-a8f0-a283a782da04",
   "metadata": {},
   "source": [
    "# EX8: PROMPTS AND LLMs USING LANGCHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f27b0eb-7c36-4c3c-9406-64202392181a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.1.23-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.35 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from langchain-openai) (0.2.38)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from langchain-openai) (1.42.0)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.7.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (0.1.116)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.35->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.5)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading regex-2024.7.24-cp312-cp312-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (3.7)\n",
      "Requirement already satisfied: certifi in /usr/local/opt/certifi/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.35->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.35->langchain-openai) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.35->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.35->langchain-openai) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.2)\n",
      "Downloading langchain_openai-0.1.23-py3-none-any.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp312-cp312-macosx_10_9_x86_64.whl (960 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m960.4/960.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.7.24-cp312-cp312-macosx_10_9_x86_64.whl (282 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.8/282.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, tiktoken, langchain-openai\n",
      "Successfully installed langchain-openai-0.1.23 regex-2024.7.24 tiktoken-0.7.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/local/Cellar/jupyterlab/4.2.3/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ba6c152-2126-4fff-9325-3e59787a82f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3n/1_0p1w191rb_3clrsh33yc9h0000gn/T/ipykernel_44921/1608970319.py:14: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
      "  print(llm(prompt))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Soleful Steps Co. \n",
      "\n",
      "\n",
      "\"Comfort Steps\"\n",
      "\n",
      "\n",
      "Socktopia\n",
      "\n",
      "\n",
      "\"Footgear Co.\" \n",
      "\n",
      "\n",
      "\"CozyFoot Co.\"\n",
      "\n",
      "\n",
      "\"Cozy Feet Co.\" \n"
     ]
    }
   ],
   "source": [
    "#from langchain.llms import OpenAI\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "#temperature indicates the randomness in the response. Between 0 to 1. Its 0 when the \n",
    "#response is determininstic and 1 when the response is more creative\n",
    "#default openAI model is text-danvinci-003\n",
    "\n",
    "llm  = OpenAI(temperature = 0.9)\n",
    "\n",
    "\n",
    "prompt = \"Suggest a good name for a company that produces socks\"\n",
    "\n",
    "print(llm(prompt))\n",
    "\n",
    "#get a deterministic response with temp = 0\n",
    "\n",
    "#generate 5 creative responses using the prompt repeatedly\n",
    "\n",
    "responses = llm.generate([prompt]*5)\n",
    "\n",
    "for name in responses.generations:\n",
    "    print(name[0].text) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c421c14b-41e0-4f24-8401-9e190ba6e2f8",
   "metadata": {},
   "source": [
    "# EX9: PROMPTING AND PROMPT TEMPLATES\n",
    "\n",
    "PROBLEM:  CREATE A PROMPT WITH ONE INPUT VARIABLE. GENERATE A SUITABLE NAME FOR A COMPANY THAT MAKES A PARTICULAR PRODUCT (USE ANY PRODUCT NAME). INPUT IS THE NAME OF THE PRODUCT.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e7ad652-a6f7-4942-9bd6-94a22e6ec72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3n/1_0p1w191rb_3clrsh33yc9h0000gn/T/ipykernel_44921/4110986079.py:23: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
      "  prediction = llm.predict(prompt_formatted_str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There could be a few different reasons why a vehicle won't start when you try to turn the key. Some possible reasons could be a dead battery, a faulty ignition switch, a bad starter motor, or a problem with the fuel system. It's also possible that there's an issue with the electrical wiring or a blown fuse. It's best to have a mechanic take a look at the vehicle and diagnose the specific problem.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "# import prompt template\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "# create the prompt\n",
    "prompt_template: str = \"\"\"/\n",
    "You are a vehicle mechanic, give responses to the following/ \n",
    "question: {question}. Do not use technical words, give easy/\n",
    "to understand responses.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template=prompt_template)\n",
    "\n",
    "# format the prompt to add variable values\n",
    "prompt_formatted_str: str = prompt.format(\n",
    "    question=\"Why won't a vehicle start on ignition?\")\n",
    "\n",
    "# instantiate the OpenAI intance\n",
    "llm = OpenAI(temperature = 0.9)\n",
    "\n",
    "# make a prediction\n",
    "prediction = llm.predict(prompt_formatted_str)\n",
    "\n",
    "# print the prediction\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5312786-8b2d-4204-a5f4-458e50729351",
   "metadata": {},
   "source": [
    "# EX10: CREATING PROMPTS WITH MULTIPLE INPUT VARIABLES\n",
    "\n",
    "PROBLEM:  GENERATE A SUITABLE NAME FOR A COMPANY THAT MAKES A PARTICULAR PRODUCT (USE ANY PRODUCT NAME) IN A SPECIFIC LANGUAGE. INPUTS ARE THE PRODUCT AND THE LANGUAGE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bfa9fe5-9573-40bf-a472-0cddc28861ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Here are a few potential names for a company that makes socks:\n",
      "\n",
      "1. Cozy Feet Co. - This name conveys a sense of comfort and warmth, which is exactly what people look for in a good pair of socks.\n",
      "2. Happy Socks - This name creates a feeling of joy and positivity, which could appeal to customers who want to brighten up their sock collection.\n",
      "3. Socksmith - This name is a play on the word \"blacksmith\" and could suggest that the company is skilled at crafting high-quality socks.\n",
      "4. Footprints - This name could evoke a sense of leaving a lasting impression, which could work well for a brand that wants to make a statement with their socks.\n",
      "5. Toesies - This is a fun and playful name that could attract customers looking for cute and quirky socks for everyday wear.\n",
      "6. Stride & Co. - This name conveys a sense of movement and could be a good fit for a company that specializes in performance or athletic socks.\n",
      "7. Snuggle Socks - This name suggests cozy and snuggly socks, which could be appealing to customers who want something soft and comfortable for lounging at home.\n",
      "8. Barefoot Basics - This name is simple and straightforward, making it clear\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"\"\"/You are a naming consultant, give responses to the following/ \n",
    "    question: {question}. Do not use technical words, give easy/\n",
    "to understand responses. Give your response in {language}\"\"\",\n",
    "    input_variables = [\"question\", \"language\"]\n",
    ")\n",
    "\n",
    "#format the prompt to add variable’s values\n",
    "prompt_formatted_str : str = prompt.format(\n",
    "    \n",
    "       question = \"Suggest a good name for a company that makes socks?\",\n",
    "       language = \"English\"\n",
    "       )\n",
    "# instantiate the OpenAI instance\n",
    "llm = OpenAI(temperature = 0.9)\n",
    "\n",
    "# make a prediction\n",
    "prediction = llm.predict(prompt_formatted_str)\n",
    "\n",
    "# print the prediction\n",
    "print(prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
